<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>消息中间件面试 xianxin 志强网</title><meta name="keywords" content="消息中间件,RabbitMQ,Kafka,面试"><meta name="description" content="志强博客"><link rel="shortcut icon" type="image/x-icon" href="/img/favicon.ico"><link rel="stylesheet" href="/css/blog.css"><link rel="stylesheet" href="/libs/layui/css/layui.css"><script src="/libs/layui/layui.js"></script><script src="/js/blog.js"></script><meta name="generator" content="Hexo 7.3.0"></head><body class="lay-blog"><div class="header"><div class="header-wrap"><h1 class="logo pull-left"><a href="/"><img src="/img/logo.png" alt="" class="logo-img"> <img src="/img/logo-text.png" alt="" class="logo-text"></a></h1><form class="layui-form blog-seach pull-left" method="get" action="https://www.google.com/search?"><div class="layui-form-item blog-sewrap"><div class="layui-input-block blog-sebox"><i class="layui-icon layui-icon-search"></i> <input type="text" name="q" lay-verify="title" autocomplete="off" class="layui-input"> <input type="hidden" name="source" value="https://www.zhiqiang.wang"></div></div></form><div class="blog-nav pull-right"><ul class="layui-nav pull-left"><li class="layui-nav-item"><a href="/">Home</a></li><li class="layui-nav-item"><a href="/about">About</a></li><li class="layui-nav-item"><a href="/archives">Archives</a></li><li class="layui-nav-item"><a href="/tags">Tags</a></li><li class="layui-nav-item"><a href="/sitemap.xml">RSS</a></li></ul></div></div></div><div class="container-wrap"><div class="container"><div class="contar-wrap"><div class="item"><div class="item-box"><p class="layui-breadcrumb" style="visibility:inherit"><a href="/">首页 </a><a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/">中间件</a></p><h3>消息中间件面试</h3><h5>发布于：<span> 2024-04-26</span></h5><div class="post-meta"><a href="/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"><button type="button" class="layui-btn layui-btn-sm layui-bg-orange">#消息中间件</button> </a><a href="/tags/RabbitMQ/"><button type="button" class="layui-btn layui-btn-sm layui-bg-orange">#RabbitMQ</button> </a><a href="/tags/Kafka/"><button type="button" class="layui-btn layui-btn-sm layui-bg-orange">#Kafka</button> </a><a href="/tags/%E9%9D%A2%E8%AF%95/"><button type="button" class="layui-btn layui-btn-sm layui-bg-orange">#面试</button></a></div><hr class="layui-border-orange"><div class="layui-content"><p class="lay-content page-content"></p><h1 id="为什么使用MQ？MQ的优点"><a href="#为什么使用MQ？MQ的优点" class="headerlink" title="为什么使用MQ？MQ的优点"></a>为什么使用MQ？MQ的优点</h1><ul><li>异步处理 - 相比于传统的串行、并行方式，提高了系统吞吐量。</li><li>应用解耦 - 系统间通过消息通信，不用关心其他系统的处理。</li><li>流量削锋 - 可以通过消息队列长度控制请求量；可以缓解短时间内的高并发请求。</li><li>日志处理 - 解决大量日志传输。</li><li>消息通讯 - 消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。</li></ul><h1 id="消息队列有什么优缺点？RabbitMQ有什么优缺点？"><a href="#消息队列有什么优缺点？RabbitMQ有什么优缺点？" class="headerlink" title="消息队列有什么优缺点？RabbitMQ有什么优缺点？"></a>消息队列有什么优缺点？RabbitMQ有什么优缺点？</h1><p>优点：</p><p>（1）解耦：将系统按照不同的业务功能拆分出来，消息生产者只管把消息发布到 MQ 中而不用管谁来取，消息消费者只管从 MQ 中取消息而不管是谁发布的。消息生产者和消费者都不知道对方的存在；</p><p>（2）异步：主流程只需要完成业务的核心功能；对于业务非核心功能，将消息放入到消息队列之中进行异步处理，减少请求的等待，提高系统的总体性能；</p><p>（3）削峰&#x2F;限流：将所有请求都写到消息队列中，消费服务器按照自身能够处理的请求数从队列中拿到请求，防止请求并发过高将系统搞崩溃；</p><p>缺点：</p><p>（1）系统的可用性降低：系统引用的外部依赖越多，越容易挂掉，如果MQ 服务器挂掉，那么可能会导致整套系统崩溃。这时就要考虑如何保证消息队列的高可用了</p><p>（2）系统复杂度提高：加入消息队列之后，需要保证消息没有重复消费、如何处理消息丢失的情况、如何保证消息传递的有序性等问题；</p><p>（3）数据一致性问题：A 系统处理完了直接返回成功了，使用者都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，就会导致数据不一致了</p><h1 id="Kafka、ActiveMQ、RabbitMQ、RocketMQ-有什么优缺点？"><a href="#Kafka、ActiveMQ、RabbitMQ、RocketMQ-有什么优缺点？" class="headerlink" title="Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？"></a>Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？</h1><table><thead><tr><th>ActiveMQ</th><th>RabbitMQ</th><th>RocketMQ</th><th>Kafka</th><th>ZeroMQ</th><th></th></tr></thead><tbody><tr><td>单机吞吐量</td><td>比RabbitMQ低</td><td>2.6w&#x2F;s（消息做持久化）</td><td>11.6w&#x2F;s</td><td>17.3w&#x2F;s</td><td>29w&#x2F;s</td></tr><tr><td>开发语言</td><td>Java</td><td>Erlang</td><td>Java</td><td>Scala&#x2F;Java</td><td>C</td></tr><tr><td>主要维护者</td><td>Apache</td><td>Mozilla&#x2F;Spring</td><td>Alibaba</td><td>Apache</td><td>iMatix，创始人已去世</td></tr><tr><td>成熟度</td><td>成熟</td><td>成熟</td><td>开源版本不够成熟</td><td>比较成熟</td><td>只有C、PHP等版本成熟</td></tr><tr><td>订阅形式</td><td>点对点(p2p)、广播（发布-订阅）</td><td>提供了4种：direct, topic ,Headers和fanout。fanout就是广播模式</td><td>基于topic&#x2F;messageTag以及按照消息类型、属性进行正则匹配的发布订阅模式</td><td>基于topic以及按照topic进行正则匹配的发布订阅模式</td><td>点对点(p2p)</td></tr><tr><td>持久化</td><td>支持少量堆积</td><td>支持少量堆积</td><td>支持大量堆积</td><td>支持大量堆积</td><td>不支持</td></tr><tr><td>顺序消息</td><td>不支持</td><td>不支持</td><td>支持</td><td>支持</td><td>不支持</td></tr><tr><td>性能稳定性</td><td>好</td><td>好</td><td>一般</td><td>较差</td><td>很好</td></tr><tr><td>集群方式</td><td>支持简单集群模式，比如’主-备’，对高级集群模式支持不好。</td><td>支持简单集群，’复制’模式，对高级集群模式支持不好。</td><td>常用 多对’Master-Slave’ 模式，开源版本需手动切换Slave变成Master</td><td>天然的‘Leader-Slave’无状态集群，每台服务器既是Master也是Slave</td><td>不支持</td></tr><tr><td>管理界面</td><td>一般</td><td>较好</td><td>一般</td><td>无</td><td>无</td></tr></tbody></table><p>一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，</p><p>后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；</p><p>不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 <a target="_blank" rel="noopener" href="https://github.com/apache/rocketmq">Apache</a>，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，</p><p>所以<strong>中小型公司</strong>，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；<strong>大型公司</strong>，基础架构研发实力较强，用 RocketMQ 是很好的选择。</p><p>如果是<strong>大数据领域</strong>的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。</p><h1 id="MQ-有哪些常见问题？如何解决这些问题？"><a href="#MQ-有哪些常见问题？如何解决这些问题？" class="headerlink" title="MQ 有哪些常见问题？如何解决这些问题？"></a>MQ 有哪些常见问题？如何解决这些问题？</h1><h2 id="消息的顺序问题"><a href="#消息的顺序问题" class="headerlink" title="消息的顺序问题"></a>消息的顺序问题</h2><p>消息有序指的是可以按照消息的发送顺序来消费。</p><p>假如生产者产生了 2 条消息：M1、M2，假定 M1 发送到 S1，M2 发送到 S2，如果要保证 M1 先于 M2 被消费，怎么做？</p><p>解决方案：保证生产者 - MQServer - 消费者是一对一对一的关系</p><p>缺陷：</p><ul><li>并行度就会成为消息系统的瓶颈（吞吐量不够）</li><li>更多的异常处理，比如：只要消费端出现问题，就会导致整个处理流程阻塞，我们不得不花费更多的精力来解决阻塞的问题。 （2）通过合理的设计或者将问题分解来规避。</li><li>不关注乱序的应用实际大量存在</li><li>队列无序并不意味着消息无序 所以从业务层面来保证消息的顺序而不仅仅是依赖于消息系统，是一种更合理的方式。</li></ul><h2 id="消息的重复问题"><a href="#消息的重复问题" class="headerlink" title="消息的重复问题"></a>消息的重复问题</h2><p>造成消息重复的根本原因是：网络不可达。</p><p>所以解决这个问题的办法就是绕过这个问题。那么问题就变成了：如果消费端收到两条一样的消息，应该怎样处理？</p><p>消费端处理消息的业务逻辑保持幂等性。只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现。利用一张日志表来记录已经处理成功的消息的 ID，如果新到的消息 ID 已经在日志表中，那么就不再处理这条消息。</p><h1 id="生产者消息的过程"><a href="#生产者消息的过程" class="headerlink" title="生产者消息的过程"></a>生产者消息的过程</h1><p>（1）Producer 先连接到 Broker，建立连接 Connection，开启一个信道 channel</p><p>（2）Producer 声明一个交换器并设置好相关属性</p><p>（3）Producer 声明一个队列并设置好相关属性</p><p>（4）Producer 通过绑定键将交换器和队列绑定起来</p><p>（5）Producer 发送消息到 Broker，其中包含路由键、交换器等信息</p><p>（6）交换器根据接收到的路由键查找匹配的队列</p><p>（7）如果找到，将消息存入对应的队列，如果没有找到，会根据生产者的配置丢弃或者退回给生产者。</p><p>（8）关闭信道</p><h1 id="消费者接收消息过程："><a href="#消费者接收消息过程：" class="headerlink" title="消费者接收消息过程："></a>消费者接收消息过程：</h1><p>（1）Producer 先连接到 Broker，建立连接 Connection，开启一个信道 channel</p><p>（2）向 Broker 请求消费相应队列中消息，可能会设置响应的回调函数。</p><p>（3）等待 Broker 回应并投递相应队列中的消息，接收消息。</p><p>（4）消费者确认收到的消息，ack。</p><p>（5）RabbitMQ从队列中删除已经确定的消息。</p><p>（6）关闭信道</p><h1 id="什么是RabbitMQ？"><a href="#什么是RabbitMQ？" class="headerlink" title="什么是RabbitMQ？"></a>什么是RabbitMQ？</h1><p>RabbitMQ是一款开源的，Erlang编写的，基于AMQP协议的消息中间件</p><h1 id="rabbitmq-的使用场景"><a href="#rabbitmq-的使用场景" class="headerlink" title="rabbitmq 的使用场景"></a>rabbitmq 的使用场景</h1><p>（1）服务间异步通信</p><p>（2）顺序消费</p><p>（3）定时任务</p><p>（4）请求削峰</p><h1 id="RabbitMQ基本概念"><a href="#RabbitMQ基本概念" class="headerlink" title="RabbitMQ基本概念"></a>RabbitMQ基本概念</h1><ul><li>Broker： 简单来说就是消息队列服务器实体</li><li>Exchange： 消息交换机，它指定消息按什么规则，路由到哪个队列</li><li>Queue： 消息队列载体，每个消息都会被投入到一个或多个队列</li><li>Binding： 绑定，它的作用就是把exchange和queue按照路由规则绑定起来</li><li>Routing Key： 路由关键字，exchange根据这个关键字进行消息投递</li><li>VHost： vhost 可以理解为虚拟 broker ，即 mini-RabbitMQ server。其内部均含有独立的 queue、exchange 和 binding 等，但最最重要的是，其拥有独立的权限系统，可以做到 vhost 范围的用户控制。当然，从 RabbitMQ 的全局角度，vhost 可以作为不同权限隔离的手段（一个典型的例子就是不同的应用可以跑在不同的 vhost 中）。</li><li>Producer： 消息生产者，就是投递消息的程序</li><li>Consumer： 消息消费者，就是接受消息的程序</li><li>Channel： 消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务</li></ul><p>由Exchange、Queue、RoutingKey三个才能决定一个从Exchange到Queue的唯一的线路。</p><h1 id="RabbitMQ的构造："><a href="#RabbitMQ的构造：" class="headerlink" title="RabbitMQ的构造："></a>RabbitMQ的构造：</h1><p>RabbitMQ 是 AMQP 协议的一个开源实现，所以其内部实际上也是 AMQP 中的基本概念：</p><p>（1）生产者Publisher：生产消息，就是投递消息的一方。消息一般包含两个部分：消息体（payload）和标签（Label）</p><p>（2）消费者Consumer：消费消息，也就是接收消息的一方。消费者连接到RabbitMQ服务器，并订阅到队列上。消费消息时只消费消息体，丢弃标签。</p><p>（3）Broker服务节点：表示消息队列服务器实体。一般情况下一个Broker可以看做一个RabbitMQ服务器。</p><p>（4）Queue：消息队列，用来存放消息。一个消息可投入一个或多个队列，多个消费者可以订阅同一队列，这时队列中的消息会被平摊（轮询）给多个消费者进行处理。</p><p>（5）Exchange：交换器，接受生产者发送的消息，根据路由键将消息路由到绑定的队列上。</p><p>（6）Routing Key： 路由关键字，用于指定这个消息的路由规则，需要与交换器类型和绑定键(Binding Key)联合使用才能最终生效。 （7）Binding：绑定，通过绑定将交换器和队列关联起来，一般会指定一个BindingKey，通过BindingKey，交换器就知道将消息路由给哪个队列了。</p><p>（8）Connection ：网络连接，比如一个TCP连接，用于连接到具体broker</p><p>（9）Channel： 信道，AMQP 命令都是在信道中进行的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接，一个TCP连接可以用多个信道。客户端可以建立多个channel，每个channel表示一个会话任务。</p><p>（10）Message：消息，由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。</p><p>（11）Virtual host：虚拟主机，用于逻辑隔离，表示一批独立的交换器、消息队列和相关对象。一个Virtual host可以有若干个Exchange和Queue，同一个Virtual host不能有同名的Exchange或Queue。最重要的是，其拥有独立的权限系统，可以做到 vhost 范围的用户控制。当然，从 RabbitMQ 的全局角度，vhost 可以作为不同权限隔离的手段</p><h1 id="RabbitMQ的工作模式"><a href="#RabbitMQ的工作模式" class="headerlink" title="RabbitMQ的工作模式"></a>RabbitMQ的工作模式</h1><h2 id="simple模式（即最简单的收发模式）"><a href="#simple模式（即最简单的收发模式）" class="headerlink" title="simple模式（即最简单的收发模式）"></a>simple模式（即最简单的收发模式）</h2><ol><li><p>消息产生消息，将消息放入队列</p></li><li><p>消息的消费者(consumer) 监听 消息队列,如果队列中有消息,就消费掉,消息被拿走后,自动从队列中删除(隐患 消息可能没有被消费者正确处理,已经从队列中消失了,造成消息的丢失，这里可以设置成手动的ack,但如果设置成手动ack，处理完后要及时发送ack消息给队列，否则会造成内存溢出)。</p></li></ol><h2 id="work工作模式-资源的竞争"><a href="#work工作模式-资源的竞争" class="headerlink" title="work工作模式(资源的竞争)"></a>work工作模式(资源的竞争)</h2><p>消息产生者将消息放入队列消费者可以有多个消费者1,消费者2同时监听同一个队列,消息被消费。C1 C2共同争抢当前的消息队列内容,谁先拿到谁负责消费消息(隐患：高并发情况下,默认会产生某一个消息被多个消费者共同使用,可以设置一个开关(syncronize) 保证一条消息只能被一个消费者使用)。</p><h2 id="publish-subscribe发布订阅-共享资源"><a href="#publish-subscribe发布订阅-共享资源" class="headerlink" title="publish&#x2F;subscribe发布订阅(共享资源)"></a>publish&#x2F;subscribe发布订阅(共享资源)</h2><ol><li><p>每个消费者监听自己的队列；</p></li><li><p>生产者将消息发给broker，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收到消息。</p></li></ol><h2 id="routing路由模式"><a href="#routing路由模式" class="headerlink" title="routing路由模式"></a>routing路由模式</h2><ol><li><p>消息生产者将消息发送给交换机按照路由判断,路由是字符串(info) 当前产生的消息携带路由字符(对象的方法),交换机根据路由的key,只能匹配上路由key对应的消息队列,对应的消费者才能消费消息;</p></li><li><p>根据业务功能定义路由字符串</p></li><li><p>从系统的代码逻辑中获取对应的功能字符串,将消息任务扔到对应的队列中。</p></li><li><p>业务场景:error 通知;EXCEPTION;错误通知的功能;传统意义的错误通知;客户通知;利用key路由,可以将程序中的错误封装成消息传入到消息队列中,开发者可以自定义消费者,实时接收错误;</p></li></ol><h2 id="topic-主题模式-路由模式的一种"><a href="#topic-主题模式-路由模式的一种" class="headerlink" title="topic 主题模式(路由模式的一种)"></a>topic 主题模式(路由模式的一种)</h2><ol><li><p>星号井号代表通配符</p></li><li><p>星号代表多个单词,井号代表一个单词</p></li><li><p>路由功能添加模糊匹配</p></li><li><p>消息产生者产生消息,把消息交给交换机</p></li><li><p>交换机根据key的规则模糊匹配到对应的队列,由队列的监听消费者接收消息消费</p></li></ol><p>（在我的理解看来就是routing查询的一种模糊匹配，就类似sql的模糊查询方式）</p><h1 id="如何保证RabbitMQ消息的顺序性？"><a href="#如何保证RabbitMQ消息的顺序性？" class="headerlink" title="如何保证RabbitMQ消息的顺序性？"></a>如何保证RabbitMQ消息的顺序性？</h1><p>拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。</p><h1 id="消息如何分发"><a href="#消息如何分发" class="headerlink" title="消息如何分发"></a>消息如何分发</h1><p>若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者（前提是消费者能够正常处理消息并进行确认）。通过路由可实现多消费的功能</p><h3 id="消息怎么路由？"><a href="#消息怎么路由？" class="headerlink" title="消息怎么路由？"></a>消息怎么路由？</h3><p>消息提供方-&gt;路由-&gt;一至多个队列消息发布到交换器时，消息将拥有一个路由键（routing key），在消息创建时设定。通过队列路由键，可以把队列绑定到交换器上。消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；</p><p>常用的交换器主要分为一下三种：</p><p>fanout：如果交换器收到消息，将会广播到所有绑定的队列上</p><p>direct：如果路由键完全匹配，消息就被投递到相应的队列</p><p>topic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符</p><h3 id="消息基于什么传输？"><a href="#消息基于什么传输？" class="headerlink" title="消息基于什么传输？"></a>消息基于什么传输？</h3><p>由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。</p><h3 id="如何保证消息不被重复消费？或者说，如何保证消息消费时的幂等性？"><a href="#如何保证消息不被重复消费？或者说，如何保证消息消费时的幂等性？" class="headerlink" title="如何保证消息不被重复消费？或者说，如何保证消息消费时的幂等性？"></a>如何保证消息不被重复消费？或者说，如何保证消息消费时的幂等性？</h3><p>正常情况下，消费者在消费消息后，会给消息队列发送一个确认，消息队列接收后就知道消息已经被成功消费了，然后就从队列中删除该消息，也就不会将该消息再发送给其他消费者了。不同消息队列发出的确认消息形式不同，RabbitMQ是通过发送一个ACK确认消息。但是因为网络故障，消费者发出的确认并没有传到消息队列，导致消息队列不知道该消息已经被消费，然后就再次消息发送给了其他消费者，从而造成重复消费的情况。</p><p>重复消费问题的解决思路是：保证消息的唯一性，即使多次传输，也不让消息的多次消费带来影响，也就是保证消息等幂性；幂等性指一个操作执行任意多次所产生的影响均与一次执行的影响相同。具体解决方案如下：</p><p>（1）改造业务逻辑，使得在重复消费时也不影响最终的结果。例如对SQL语句： update t1 set money &#x3D; 150 where id &#x3D; 1 and money &#x3D; 100; 做了个前置条件判断，即 money &#x3D; 100 的情况下才会做更新，更通用的是做个 version 即版本号控制，对比消息中的版本号和数据库中的版本号。</p><p>（2）基于数据库的的唯一主键进行约束。消费完消息之后，到数据库中做一个 insert 操作，如果出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。</p><p>（3）通过记录关键的key，当重复消息过来时，先判断下这个key是否已经被处理过了，如果没处理再进行下一步。</p><p>① 通过数据库：比如处理订单时，记录订单ID，在消费前，去数据库中进行查询该记录是否存在，如果存在则直接返回。</p><p>② 使用全局唯一ID，再配合第三组主键做消费记录，比如使用 redis 的 set 结构，生产者发送消息时给消息分配一个全局ID，在每次消费者开始消费前，先去redis中查询有没有消费记录，如果消费过则不进行处理，如果没消费过，则进行处理，消费完之后，就将这个ID以k-v的形式存入redis中(过期时间根据具体情况设置)。</p><h1 id="如何保证消息不丢失，进行可靠性传输？"><a href="#如何保证消息不丢失，进行可靠性传输？" class="headerlink" title="如何保证消息不丢失，进行可靠性传输？"></a>如何保证消息不丢失，进行可靠性传输？</h1><p>对于消息的可靠性传输，每种MQ都要从三个角度来分析：生产者丢数据、消息队列丢数据、消费者丢数据。</p><h2 id="生产者丢数据："><a href="#生产者丢数据：" class="headerlink" title="生产者丢数据："></a>生产者丢数据：</h2><p>RabbitMQ提供事务机制（transaction）和确认机制（confirm）两种模式来确保生产者不丢消息。</p><h2 id="持久化设置"><a href="#持久化设置" class="headerlink" title="持久化设置"></a>持久化设置</h2><p>（1）创建queue的时候，将queue的持久化标志durable在设置为true，代表是一个持久的队列，这样就可以保证 rabbitmq 持久化 queue 的元数据，但是不会持久化queue里的数据；</p><p>（2）发送消息的时候将 deliveryMode 设置为 2，将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。 这样设置以后，RabbitMQ 就算挂了，重启后也能恢复数据。在消息还没有持久化到硬盘时，可能服务已经死掉，这种情况可以通过引入镜像队列，但也不能保证消息百分百不丢失（整个集群都挂掉）</p><h3 id="事务机制："><a href="#事务机制：" class="headerlink" title="事务机制："></a>事务机制：</h3><p>发送消息前，开启事务（channel.txSelect()），然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()），如果发送成功则提交事务（channel.txCommit()）该方式的缺点是生产者发送消息会同步阻塞等待发送结果是成功还是失败，导致生产者发送消息的吞吐量降下降。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">// 开启事务</span><br><span class="line">channel.txSelect</span><br><span class="line">try &#123;</span><br><span class="line">    // 发送消息</span><br><span class="line">&#125; catch(Exception e)&#123;</span><br><span class="line">    // 回滚事务</span><br><span class="line">    channel.txRollback;</span><br><span class="line">    //再次重试发送这条消息</span><br><span class="line">    ....</span><br><span class="line">&#125;      </span><br><span class="line">//提交事务</span><br><span class="line">channel.txCommit;</span><br></pre></td></tr></table></figure><h3 id="确认机制："><a href="#确认机制：" class="headerlink" title="确认机制："></a>确认机制：</h3><p>生产环境常用的是confirm模式。生产者将信道 channel 设置成 confirm 模式，一旦 channel 进入 confirm 模式，所有在该信道上发布的消息都将会被指派一个唯一的ID，一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个确认给生产者（包含消息的唯一ID），这样生产者就知道消息已经正确到达目的队列了。如果rabbitMQ没能处理该消息，也会发送一个Nack消息给你，这时就可以进行重试操作。</p><p>Confirm模式最大的好处在于它是异步的，一旦发布消息，生产者就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者便可以通过回调方法来处理该确认消息。</p><p>处理Ack和Nack的代码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">channel.addConfirmListener(new ConfirmListener() &#123;</span><br><span class="line">  @Override</span><br><span class="line">  public void handleNack(long deliveryTag, boolean multiple) throws IOException &#123;</span><br><span class="line">    System.out.println(&quot;nack: deliveryTag = &quot;+deliveryTag+&quot; multiple: &quot;+multiple);</span><br><span class="line">  &#125;</span><br><span class="line">  @Override</span><br><span class="line">  public void handleAck(long deliveryTag, boolean multiple) throws IOException &#123;</span><br><span class="line">  System.out.println(&quot;ack: deliveryTag = &quot;+deliveryTag+&quot; multiple: &quot;+multiple);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;); </span><br></pre></td></tr></table></figure><h3 id="消费者丢数据："><a href="#消费者丢数据：" class="headerlink" title="消费者丢数据："></a>消费者丢数据：</h3><p>消费者丢数据一般是因为采用了自动确认消息模式。该模式下，虽然消息还在处理中，但是消费中者会自动发送一个确认，通知 RabbitMQ 已经收到消息了，这时 RabbitMQ 就会立即将消息删除。这种情况下，如果消费者出现异常而未能处理消息，那就会丢失该消息。<br>解决方案就是采用手动确认消息，设置 autoAck &#x3D; False，等到消息被真正消费之后，再手动发送一个确认信号，即使中途消息没处理完，但是服务器宕机了，那 RabbitMQ 就收不到发的ack，然后 RabbitMQ 就会将这条消息重新分配给其他的消费者去处理。<br>但是 RabbitMQ 并没有使用超时机制，RabbitMQ 仅通过与消费者的连接来确认是否需要重新发送消息，也就是说，只要连接不中断，RabbitMQ 会给消费者足够长的时间来处理消息。另外，采用手动确认消息的方式，我们也需要考虑一下几种特殊情况：</p><p>如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被消费，然后重新分发给下一个订阅的消费者，所以存在消息重复消费的隐患 如果消费者接收到消息却没有确认消息，连接也未断开，则RabbitMQ认为该消费者繁忙，将不会给该消费者分发更多的消息 需要注意的点：</p><p>1、消息可靠性增强了，性能就下降了，因为写磁盘比写 RAM 慢的多，两者的吞吐量可能有 10 倍的差距。所以，是否要对消息进行持久化，需要综合考虑业务场景、性能需要，以及可能遇到的问题。若想达到单RabbitMQ服务器 10W 条&#x2F;秒以上的消息吞吐量，则要么使用其他的方式来确保消息的可靠传输，要么使用非常快速的存储系统以支持全持久化，例如使用 SSD。或者仅对关键消息作持久化处理，且应该保证关键消息的量不会导致性能瓶颈。</p><p>2、当设置 autoAck &#x3D; False 时，如果忘记手动 ack，那么将会导致大量任务都处于 Unacked 状态，造成队列堆积，直至消费者断开才会重新回到队列。解决方法是及时 ack，确保异常时 ack 或者拒绝消息。</p><p>3、启用消息拒绝或者发送 nack 后导致死循环的问题：如果在消息处理异常时，直接拒绝消息，消息会重新进入队列。这时候如果消息再次被处理时又被拒绝 。这样就会形成死循环。</p><h1 id="如何保证消息的有序性？"><a href="#如何保证消息的有序性？" class="headerlink" title="如何保证消息的有序性？"></a>如何保证消息的有序性？</h1><p>针对保证消息有序性的问题，解决方法就是保证生产者入队的顺序是有序的，出队后的顺序消费则交给消费者去保证。</p><p>方法一：拆分queue，使得一个queue只对应一个消费者。由于MQ一般都能保证内部队列是先进先出的，所以把需要保持先后顺序的一组消息使用某种算法都分配到同一个消息队列中。然后只用一个消费者单线程去消费该队列，这样就能保证消费者是按照顺序进行消费的了。但是消费者的吞吐量会出现瓶颈。如果多个消费者同时消费一个队列，还是可能会出现顺序错乱的情况，这就相当于是多线程消费了</p><p>方法二：对于多线程的消费同一个队列的情况，可以使用重试机制：比如有一个微博业务场景的操作，发微博、写评论、删除微博，这三个异步操作。如果一个消费者先执行了写评论的操作，但是这时微博都还没发，写评论一定是失败的，等一段时间。等另一个消费者，先执行发微博的操作后，再执行，就可以成功。</p><h1 id="如何确保消息正确地发送至-RabbitMQ？-如何确保消息接收方消费了消息？"><a href="#如何确保消息正确地发送至-RabbitMQ？-如何确保消息接收方消费了消息？" class="headerlink" title="如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？"></a>如何确保消息正确地发送至 RabbitMQ？ 如何确保消息接收方消费了消息？</h1><h2 id="发送方确认模式"><a href="#发送方确认模式" class="headerlink" title="发送方确认模式"></a>发送方确认模式</h2><p>将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。</p><p>一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。</p><p>如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。</p><p>发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。</p><h2 id="接收方确认机制"><a href="#接收方确认机制" class="headerlink" title="接收方确认机制"></a>接收方确认机制</h2><p>消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。</p><p>这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息。保证数据的最终一致性；</p><p>下面罗列几种特殊情况</p><ul><li>如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）</li><li>如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。</li></ul><h1 id="如何保证RabbitMQ消息的可靠传输？"><a href="#如何保证RabbitMQ消息的可靠传输？" class="headerlink" title="如何保证RabbitMQ消息的可靠传输？"></a>如何保证RabbitMQ消息的可靠传输？</h1><p>消息不可靠的情况可能是消息丢失，劫持等原因；</p><p>丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；</p><p><strong>生产者丢失消息</strong>：从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；</p><p>transaction机制就是说：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；</p><p>confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；</p><p>rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；</p><p>如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。</p><p><strong>消息队列丢数据</strong>：消息持久化。</p><p>处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。</p><p>这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。</p><p>这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。</p><p>那么如何持久化呢？</p><p>这里顺便说一下吧，其实也很容易，就下面两步</p><ol><li>将queue的持久化标识durable设置为true,则代表是一个持久的队列</li><li>发送消息的时候将deliveryMode&#x3D;2</li></ol><p>这样设置以后，即使rabbitMQ挂了，重启后也能恢复数据</p><p><strong>消费者丢失消息</strong>：消费者丢数据一般是因为采用了自动确认消息模式，改为手动确认消息即可！</p><p>消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；</p><p>如果这时处理消息失败，就会丢失该消息；</p><p>解决方案：处理消息成功后，手动回复确认消息。</p><h1 id="为什么不应该对所有的-message-都使用持久化机制？"><a href="#为什么不应该对所有的-message-都使用持久化机制？" class="headerlink" title="为什么不应该对所有的 message 都使用持久化机制？"></a>为什么不应该对所有的 message 都使用持久化机制？</h1><p>首先，必然导致性能的下降，因为写磁盘比写 RAM 慢的多，message 的吞吐量可能有 10 倍的差距。</p><p>其次，message 的持久化机制用在 RabbitMQ 的内置 cluster 方案时会出现“坑爹”问题。矛盾点在于，若 message 设置了 persistent 属性，但 queue 未设置 durable 属性，那么当该 queue 的 owner node 出现异常后，在未重建该 queue 前，发往该 queue 的 message 将被 blackholed ；若 message 设置了 persistent 属性，同时 queue 也设置了 durable 属性，那么当 queue 的 owner node 异常且无法重启的情况下，则该 queue 无法在其他 node 上重建，只能等待其 owner node 重启后，才能恢复该 queue 的使用，而在这段时间内发送给该 queue 的 message 将被 blackholed 。</p><p>所以，是否要对 message 进行持久化，需要综合考虑性能需要，以及可能遇到的问题。若想达到 100,000 条&#x2F;秒以上的消息吞吐量（单 RabbitMQ 服务器），则要么使用其他的方式来确保 message 的可靠 delivery ，要么使用非常快速的存储系统以支持全持久化（例如使用 SSD）。另外一种处理原则是：仅对关键消息作持久化处理（根据业务重要程度），且应该保证关键消息的量不会导致性能瓶颈。</p><h3 id="如何保证高可用的RabbitMQ-的集群"><a href="#如何保证高可用的RabbitMQ-的集群" class="headerlink" title="如何保证高可用的RabbitMQ 的集群"></a>如何保证高可用的RabbitMQ 的集群</h3><p>RabbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。</p><p><strong>单机模式</strong>，就是 Demo 级别的，一般就是你本地启动了玩玩儿的?，没人生产用单机模式</p><p><strong>普通集群模式</strong>，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。</p><p><strong>镜像集群模式</strong>：这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。这样的话，好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。</p><h1 id="如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？"><a href="#如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？" class="headerlink" title="如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？"></a>如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？</h1><p>消息积压处理办法：临时紧急扩容：</p><p>先修复 consumer 的问题，确保其恢复消费速度，然后将现有 cnosumer 都停掉。 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。 MQ中消息失效：假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。</p><p>mq消息队列块满了：如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。</p><h1 id="如何处理消息堆积情况"><a href="#如何处理消息堆积情况" class="headerlink" title="如何处理消息堆积情况?"></a>如何处理消息堆积情况?</h1><p>场景题：几千万条数据在MQ里积压了七八个小时。</p><p>出现该问题的原因：</p><p>消息堆积往往是生产者的生产速度与消费者的消费速度不匹配导致的。有可能就是消费者消费能力弱，渐渐地消息就积压了，也有可能是因为消息消费失败反复复重试造成的，也有可能是消费端出了问题，导致不消费了或者消费极其慢。比如，消费端每次消费之后要写mysql，结果mysql挂了，消费端hang住了不动了，或者消费者本地依赖的一个东西挂了，导致消费者挂了。</p><p>所以如果是 bug 则处理 bug；如果是因为本身消费能力较弱，则优化消费逻辑，比如优化前是一条一条消息消费处理的，那么就可以批量处理进行优化。</p><h2 id="临时扩容，快速处理积压的消息："><a href="#临时扩容，快速处理积压的消息：" class="headerlink" title="临时扩容，快速处理积压的消息："></a>临时扩容，快速处理积压的消息：</h2><p>（1）先修复 consumer 的问题，确保其恢复消费速度，然后将现有的 consumer 都停掉；</p><p>（2）临时创建原先 N 倍数量的 queue ，然后写一个临时分发数据的消费者程序，将该程序部署上去消费队列中积压的数据，消费之后不做任何耗时处理，直接均匀轮询写入临时建立好的 N 倍数量的 queue 中；</p><p>（3）接着，临时征用 N 倍的机器来部署 consumer，每个 consumer 消费一个临时 queue 的数据</p><p>（4）等快速消费完积压数据之后，恢复原先部署架构 ，重新用原先的 consumer 机器消费消息。</p><p>这种做法相当于临时将 queue 资源和 consumer 资源扩大 N 倍，以正常 N 倍速度消费。</p><h2 id="恢复队列中丢失的数据："><a href="#恢复队列中丢失的数据：" class="headerlink" title="恢复队列中丢失的数据："></a>恢复队列中丢失的数据：</h2><p>如果使用的是 rabbitMQ，并且设置了过期时间，消息在 queue 里积压超过一定的时间会被 rabbitmq 清理掉，导致数据丢失。这种情况下，实际上队列中没有什么消息挤压，而是丢了大量的消息。所以就不能说增加 consumer 消费积压的数据了，这种情况可以采取 “批量重导” 的方案来进行解决。在流量低峰期，写一个程序，手动去查询丢失的那部分数据，然后将消息重新发送到mq里面，把丢失的数据重新补回来。</p><h2 id="MQ长时间未处理导致MQ写满的情况如何处理："><a href="#MQ长时间未处理导致MQ写满的情况如何处理：" class="headerlink" title="MQ长时间未处理导致MQ写满的情况如何处理："></a>MQ长时间未处理导致MQ写满的情况如何处理：</h2><p>如果消息积压在MQ里，并且长时间都没处理掉，导致MQ都快写满了，这种情况肯定是临时扩容方案执行太慢，这种时候只好采用 “丢弃+批量重导” 的方式来解决了。首先，临时写个程序，连接到mq里面消费数据，消费一个丢弃一个，快速消费掉积压的消息，降低MQ的压力，然后在流量低峰期时去手动查询重导丢失的这部分数据。</p><h1 id="如何保证消息队列的高可用？"><a href="#如何保证消息队列的高可用？" class="headerlink" title="如何保证消息队列的高可用？"></a>如何保证消息队列的高可用？</h1><p>RabbitMQ 是基于主从（非分布式）做高可用性的，RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式</p><h3 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h3><p>一般没人生产用单机模式</p><h3 id="普通集群模式"><a href="#普通集群模式" class="headerlink" title="普通集群模式"></a>普通集群模式</h3><p>普通集群模式用于提高系统的吞吐量，通过添加节点来线性扩展消息队列的吞吐量。也就是在多台机器上启动多个 RabbitMQ 实例，而队列 queue 的消息只会存放在其中一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。消费的时候，如果连接到了另外的实例，那么该实例就会从数据实际所在的实例上的queue拉取消息过来，就是说让集群中多个节点来服务某个 queue 的读写操作但普通集群模式的缺点在于：无高可用性，queue所在的节点宕机了，其他实例就无法从那个实例拉取数据；RabbitMQ 内部也会产生大量的数据传输。</p><h3 id="镜像队列集群模式"><a href="#镜像队列集群模式" class="headerlink" title="镜像队列集群模式"></a>镜像队列集群模式</h3><p>镜像队列集群是RabbitMQ 真正的高可用模式，集群中一般会包含一个主节点master和若干个从节点slave，如果master由于某种原因失效，那么按照slave加入的时间排序，”资历最老”的slave会被提升为新的master。镜像队列下，所有的消息只会向master发送，再由master将命令的执行结果广播给slave，所以master与slave节点的状态是相同的。比如，每次写消息到 queue 时，master会自动将消息同步到各个slave实例的queue；如果消费者与slave建立连接并进行订阅消费，其实质上也是从master上获取消息，只不过看似是从slave上消费而已，比如消费者与slave建立了TCP连接并执行Basic.Get的操作，那么也是由slave将Basic.Get请求发往master，再由master准备好数据返回给slave，最后由slave投递给消费者。 从上面可以看出，队列的元数据和消息会存在于多个实例上，也就是说每个 RabbitMQ 节点都有这个 queue 的完整镜像，任何一个机器宕机了，其它机器节点还包含了这个 queue 的完整数据，其他消费者都可以到其它节点上去消费数据。</p><p>缺点：</p><p>① 性能开销大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重</p><p>② 非分布式，没有扩展性，如果 queue 的数据量大到这个机器上的容量无法容纳了，此时该方案就会出现问题了</p><p>如何开启镜像集群模式呢？</p><p>在RabbitMQ 的管理控制台Admin页面下，新增一个镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。</p><h3 id="其他："><a href="#其他：" class="headerlink" title="其他："></a>其他：</h3><p>（1）交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理方式：设置mandatory &#x3D; true，代表返回消息给生产者；设置mandatory &#x3D; false，代表直接丢弃</p><p>（2）消费者得到消息队列中的数据的方式：push 和 pull</p><p>（3）消息基于什么传输：由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。所以RabbitMQ 使用信道 channel 的方式来传输数据，信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。</p><p>（4）死信队列DLX：DLX也是一个正常的Exchange，和一般的Exchange没有任何区别。能在任何的队列上被指定，实际上就是设置某个队列的属性。当这个队列出现死信（dead message，就是没有任何消费者消费）的时候，RabbitMQ就会自动将这条消息重新发布到Exchange上去，进而被路由到另一个队列。可以监听这个队列中的消息作相应的处理。消息变为死信的几种情况：</p><p>消息被拒绝（basic.reject&#x2F;basic.nack）同时 requeue&#x3D;false（不重回队列） TTL 过期 队列达到最大长度，无法再添加 （5）延迟队列：存储对应的延迟消息，当消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。在 RabbitMQ 中并不存在延迟队列，但我们可以通过设置消息的过期时间和死信队列来实现延迟队列，消费者监听死信交换器绑定的队列，而不要监听消息发送的队列。</p><p>（6）优先级队列：优先级高的队列会先被消费，可以通过 x-max-priority 参数来实现。但是当消费速度大于生产速度且 Broker 没有堆积的情况下，优先级显得没有意义。</p><p>（7）RabbitMQ 要求集群中至少有一个磁盘节点，其他节点可以是内存节点，当节点加入或离开集群时，必须要将该变更通知到至少一个磁盘节点。如果只有一个磁盘节点，刚好又是该节点崩溃了，那么集群可以继续路由消息，但不能创建队列、创建交换器、创建绑定、添加用户、更改权限、添加或删除集群节点。也就是说集群中的唯一磁盘节点崩溃的话，集群仍然可以运行，但直到该节点恢复前，无法更改任何东西。</p><h1 id="设计MQ思路"><a href="#设计MQ思路" class="headerlink" title="设计MQ思路"></a>设计MQ思路</h1><p>比如说这个消息队列系统，我们从以下几个角度来考虑一下：</p><p>首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -&gt; topic -&gt; partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？</p><p>其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。</p><p>其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -&gt; leader &amp; follower -&gt; broker 挂了重新选举 leader 即可对外服务。</p><p>能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。</p><p></p></div><hr class="layui-border-orange"></div></div><style>.layui-content table{border-collapse:collapse;border-spacing:0;margin:10px 0;display:table}.layui-content table td,table th{padding:10px;border:1px solid #ddd;color:#333;vertical-align:middle;word-break:normal!important}.layui-content table .gutter{display:none}.layui-content figure.highlight{margin:15px 0;background:#e3e3e3;padding:0;line-height:24px;overflow-x:auto}.layui-content figure.highlight table td{border:0}.layui-content blockquote{margin:15px 0;background:#e3e3e3;border-left:3px solid #5fb878;padding:10px 0 0 20px}.layui-content ol li{margin-bottom:10px;list-style:decimal;margin-left:10px}.layui-content ul li{margin-bottom:10px;list-style:inside;margin-left:10px}.layui-content code{background-color:#e3e3e3}.layui-content a{text-decoration:underline;color:#1e9fff}body img{max-width:100%}</style></div></div></div><div class="footer"><p><span>Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> </span><span>| </span><span>Theme - <a href="https://github.com/zzqqw/hexo-theme-xianxin" target="_blank">xianxin</a></span></p><p><span>&copy; 2024</span> <span>MIT license</span></p><script async src="https://www.googletagmanager.com/gtag/js?id=G-TBH6G20B8Y"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-TBH6G20B8Y")</script></div></body></html>